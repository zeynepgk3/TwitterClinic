{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08340a8f",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d44482c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string;\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "EMOJI_PATTERN=re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           u\"\\U0001f926-\\U0001f937\"\n",
    "                           u\"\\U00010000-\\U0010ffff\"\n",
    "                           u\"\\u2640-\\u2642\"\n",
    "                           u\"\\u2600-\\u2B55\"\n",
    "                           u\"\\u200d\"\n",
    "                           u\"\\u23cf\"\n",
    "                           u\"\\u23e9\"\n",
    "                           u\"\\u231a\"\n",
    "                           u\"\\ufe0f\"  # dingbats\n",
    "                           u\"\\u3030\"\n",
    "                           \"]+\", re.UNICODE);\n",
    "PUNCT_TO_REMOVE = string.punctuation.replace(\"'\", \"\")\n",
    "STOP_WORDS=stopwords.words(\"english\")\n",
    "STOP_WORDS.extend([\"'s\",\"'m\",\"'ve\",\"s\",\"#\"])\n",
    "\n",
    "TRAIN_SPLIT = 0.6\n",
    "TEST_SPLIT = 0.2\n",
    "LEARNING_RATE = 0.1\n",
    "EPOCHS= 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a980d6e",
   "metadata": {},
   "source": [
    "## Import libraries and datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9931180b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "import re\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "\n",
    "reddit_suidiceWatch = pd.read_csv('../data/reddit_depression_suicidewatch.csv') #depression and SuicideWatch. long texts (limit it somehow). row=20365\n",
    "# depressive_tweets = pd.read_csv('depressive_tweets_processed.csv', sep = '|', header = None, usecols = range(0,9), nrows = 3200) #all depressed, no label needed. row= 4078\n",
    "tweet_mental_health_classification = pd.read_csv('../data/tweet-mental-health-classification-train.csv') # stressed, anxious, ..... first column, no column name. row= 1.048.575\n",
    "training160000 = pd.read_csv('../data/training.1600000.processed.noemoticon.csv',encoding='latin-1') # 0=negative, 2=notr, 4=positive. first column, no column name. row= 1.048.575\n",
    "\n",
    "training160000.drop(columns=training160000.columns[1:5], axis=1, inplace=True)\n",
    "column_names=[\"labels\",'tweets']\n",
    "training160000.columns = column_names\n",
    "new_cols = [\"tweets\",\"labels\"]\n",
    "training160000=training160000.reindex(columns=new_cols)\n",
    "\n",
    "# depressive_tweets.drop(columns=depressive_tweets.columns[-3:], axis=1, inplace=True)\n",
    "# depressive_tweets.drop(columns=depressive_tweets.columns[0:5], axis=1, inplace=True)\n",
    "\n",
    "# column_names_d=['tweet']\n",
    "# depressive_tweets.columns = column_names_d\n",
    "\n",
    "nlp = en_core_web_sm.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc18bbd5",
   "metadata": {},
   "source": [
    "## Inspect and Split Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413d7cd7",
   "metadata": {},
   "source": [
    "### 1.training160000 (positive, negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29b25af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive size:\n",
      "800000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>799999</th>\n",
       "      <td>I LOVE @Health4UandPets u guys r the best!!</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800000</th>\n",
       "      <td>im meeting up with one of my besties tonight! ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800001</th>\n",
       "      <td>@DaRealSunisaKim Thanks for the Twitter add, S...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   tweets    labels\n",
       "799999       I LOVE @Health4UandPets u guys r the best!!   Positive\n",
       "800000  im meeting up with one of my besties tonight! ...  Positive\n",
       "800001  @DaRealSunisaKim Thanks for the Twitter add, S...  Positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive_training160000 = training160000[training160000['labels'] == 4]\n",
    "DF_POSITIVE = positive_training160000\n",
    "print(\"positive size:\")\n",
    "DF_POSITIVE['labels'] = \"Positive\"\n",
    "print(len(DF_POSITIVE))\n",
    "DF_POSITIVE.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e98d6c3",
   "metadata": {},
   "source": [
    "### 2.reddit_suidiceWatch (Depression, Suidical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2aad5315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divideRedditTextToTweetLength(paragraph):\n",
    "    lines = []\n",
    "    line = ''\n",
    "    if(len(line) + len(paragraph) + 1 < 240):\n",
    "        return [paragraph]\n",
    "    for sentence in (s.strip()+'.' for s in paragraph.split('.')[:-1]):\n",
    "        if len(line) + len(sentence) + 1 >= 240: #overfitting.\n",
    "            lines.append(line)\n",
    "            line = sentence\n",
    "        else:                                   \n",
    "            line += ' ' + sentence  \n",
    "    print(lines)\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64b64e13",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depressive_reddit_suicide size:\n",
      "9992\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I am so exhausted of this. Just when I think I...</td>\n",
       "      <td>Suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I am 20 year old with some good friends but I ...</td>\n",
       "      <td>Suicidal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>it is looming around the corner again. It alwa...</td>\n",
       "      <td>Suicidal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets    labels\n",
       "3  I am so exhausted of this. Just when I think I...  Suicidal\n",
       "5  I am 20 year old with some good friends but I ...  Suicidal\n",
       "8  it is looming around the corner again. It alwa...  Suicidal"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# no time:( suicidal_reddit_list = [divideRedditTextToTweetLength(paragraph) for paragraph in suicidal_reddit['tweets'].tolist()]\n",
    "\n",
    "suicidal_reddit = reddit_suidiceWatch[reddit_suidiceWatch['label'] == 'SuicideWatch']\n",
    "DF_SUICIDAL = suicidal_reddit\n",
    "DF_SUICIDAL['label'] = \"Suicidal\"\n",
    "DF_SUICIDAL.rename(columns = {'text':'tweets','label':'labels'}, inplace = True)\n",
    "DF_SUICIDAL['tweets'] = DF_SUICIDAL['tweets'].str.slice(0,240) # paragrafı parçalara ayırmak yerine ilk 240ı almayı tercih ettik (şimdilik)\n",
    "\n",
    "print(\"depressive_reddit_suicide size:\")\n",
    "print(len(DF_SUICIDAL))\n",
    "DF_SUICIDAL.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655adaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "depressive_reddit_depression size:\n",
      "10371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently went through a breakup and she said...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not know how to navigate these feelings, ...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So I have been with my bf for 5 months , and h...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I have been severly bullied since i was 5 till...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>My mom made me go to a camp that she knows I h...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20355</th>\n",
       "      <td>cannot even decide where to start. Low self es...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20359</th>\n",
       "      <td>that is what has happened to me last week. And...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20360</th>\n",
       "      <td>Ever just feel alone in a house full of people...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20361</th>\n",
       "      <td>Politicians. Neighbors. Corporations. Society....</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20362</th>\n",
       "      <td>I feel like I am just existing, but for what. ...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  tweets      labels\n",
       "0      I recently went through a breakup and she said...  Depressive\n",
       "1      I do not know how to navigate these feelings, ...  Depressive\n",
       "2      So I have been with my bf for 5 months , and h...  Depressive\n",
       "4      I have been severly bullied since i was 5 till...  Depressive\n",
       "6      My mom made me go to a camp that she knows I h...  Depressive\n",
       "...                                                  ...         ...\n",
       "20355  cannot even decide where to start. Low self es...  Depressive\n",
       "20359  that is what has happened to me last week. And...  Depressive\n",
       "20360  Ever just feel alone in a house full of people...  Depressive\n",
       "20361  Politicians. Neighbors. Corporations. Society....  Depressive\n",
       "20362  I feel like I am just existing, but for what. ...  Depressive\n",
       "\n",
       "[10371 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "depressive_reddit = reddit_suidiceWatch[reddit_suidiceWatch['label'] == 'depression']\n",
    "print(\"depressive_reddit_depression size:\")\n",
    "depressive_reddit.rename(columns = {'text':'tweets','label':'labels'}, inplace = True)\n",
    "depressive_reddit['labels'] = \"Depressive\"\n",
    "print(len(depressive_reddit))\n",
    "depressive_reddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9102bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(suicidal_reddit['tweets'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a50ea71",
   "metadata": {},
   "source": [
    "### 3.depressive_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ef4d9bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'depressive_tweets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mdepressive_tweets\u001b[49m))\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# print(depressive_tweets)\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# print(depressive_reddit)\u001b[39;00m\n\u001b[0;32m      5\u001b[0m depressive_tweets[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDepressive\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'depressive_tweets' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(depressive_tweets))\n",
    "# print(depressive_tweets)\n",
    "# print(depressive_reddit)\n",
    "\n",
    "depressive_tweets['label']='Depressive'\n",
    "depressive_tweets.rename(columns = {'tweet':'tweets','label':'labels'}, inplace = True)\n",
    "depressive_tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f73a11f",
   "metadata": {},
   "source": [
    "#### merge depressive_tweets and depressive_reddit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a75d0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I recently went through a breakup and she said...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I do not know how to navigate these feelings, ...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>So I have been with my bf for 5 months , and h...</td>\n",
       "      <td>Depressive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets      labels\n",
       "0  I recently went through a breakup and she said...  Depressive\n",
       "1  I do not know how to navigate these feelings, ...  Depressive\n",
       "2  So I have been with my bf for 5 months , and h...  Depressive"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# DF_DEPRESSIVE=pd.concat([depressive_reddit,depressive_tweets],axis=0)\n",
    "DF_DEPRESSIVE=depressive_reddit\n",
    "DF_DEPRESSIVE['tweets'] = DF_DEPRESSIVE['tweets'].str.slice(0,240)\n",
    "print(len(DF_DEPRESSIVE))\n",
    "DF_DEPRESSIVE.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833bb8ac",
   "metadata": {},
   "source": [
    "### tweet_mental_health_classification (Stressed, Anxious, Normal, Lonely)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "12be8d8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6840\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     sending solidarity whoever doctor manage incre...\n",
       "11                            feel beautiful woman sad \n",
       "18    tire fight foreign occupier fight defend homel...\n",
       "21    boy get slaughter helpless mother could scream...\n",
       "27    sad thing disinformation truth come damage alr...\n",
       "Name: tweets, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_STRESSED = tweet_mental_health_classification[tweet_mental_health_classification['labels'] == 'Stressed']\n",
    "print(len(DF_STRESSED))\n",
    "DF_STRESSED['tweets'].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "640c35fd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8388\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>need see hair amp beard gat book appointment b...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>good point remember 1013 leave alone pokie clu...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>okay ik lot people go want im make gc ashnikko...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>ron desantis danger florida democracy want pre...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>fact get mecha work boy girl doggy style posit...</td>\n",
       "      <td>Anxious</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets   labels\n",
       "1   need see hair amp beard gat book appointment b...  Anxious\n",
       "6   good point remember 1013 leave alone pokie clu...  Anxious\n",
       "8   okay ik lot people go want im make gc ashnikko...  Anxious\n",
       "14  ron desantis danger florida democracy want pre...  Anxious\n",
       "19  fact get mecha work boy girl doggy style posit...  Anxious"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_ANXIOUS = tweet_mental_health_classification[tweet_mental_health_classification['labels'] == 'Anxious']\n",
    "print(len(DF_ANXIOUS))\n",
    "DF_ANXIOUS.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22b98b40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7973\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>next time meet someone new dont ask ask love</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>raise hand junhoes ocean lotion life rent free...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>mariposa de barrio teach matter guy forever ch...</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mori wip white dress</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>im gonna say</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets  labels\n",
       "2      next time meet someone new dont ask ask love   Normal\n",
       "4  raise hand junhoes ocean lotion life rent free...  Normal\n",
       "5  mariposa de barrio teach matter guy forever ch...  Normal\n",
       "7                              mori wip white dress   Normal\n",
       "9                                      im gonna say   Normal"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_NORMAL = tweet_mental_health_classification[tweet_mental_health_classification['labels'] == 'Normal']\n",
    "print(len(DF_NORMAL))\n",
    "DF_NORMAL.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de3aae56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6788\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>surprise someone love give la senza gift box r...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>people suffer know difficult mourn one person ...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2021 im bring back tune 20142016 era aka actua...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>base abuja get 5years experience office admini...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>guess need feel comfort biden protect us evil ...</td>\n",
       "      <td>Lonely</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweets  labels\n",
       "3   surprise someone love give la senza gift box r...  Lonely\n",
       "10  people suffer know difficult mourn one person ...  Lonely\n",
       "15  2021 im bring back tune 20142016 era aka actua...  Lonely\n",
       "16  base abuja get 5years experience office admini...  Lonely\n",
       "20  guess need feel comfort biden protect us evil ...  Lonely"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DF_LONELY = tweet_mental_health_classification[tweet_mental_health_classification['labels'] == 'Lonely']\n",
    "print(len(DF_LONELY))\n",
    "DF_LONELY.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d810a160",
   "metadata": {},
   "source": [
    "## Create corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75ee4a4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Positive      800000\n",
       "Depressive     10371\n",
       "Suicidal        9992\n",
       "Anxious         8388\n",
       "Normal          7973\n",
       "Stressed        6840\n",
       "Lonely          6788\n",
       "Name: labels, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CORPUS=pd.concat([DF_LONELY,DF_NORMAL,DF_ANXIOUS,DF_STRESSED,DF_DEPRESSIVE,DF_SUICIDAL,DF_POSITIVE],axis=0)\n",
    "CORPUS.labels.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "103f42a1",
   "metadata": {},
   "source": [
    "## split test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46894b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7c0c2e81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5430 5430 1358 1358\n",
      "6378 6378 1595 1595\n",
      "6710 6710 1678 1678\n",
      "5472 5472 1368 1368\n",
      "8296 8296 2075 2075\n",
      "7993 7993 1999 1999\n",
      "640000 640000 160000 160000\n"
     ]
    }
   ],
   "source": [
    "DF_LONELY_Xtrain, DF_LONELY_Xtest, DF_LONELY_Ytrain, DF_LONELY_Ytest = train_test_split(\n",
    "    DF_LONELY.tweets,\n",
    "    DF_LONELY.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_LONELY.labels)\n",
    "print(len(DF_LONELY_Xtrain), len(DF_LONELY_Ytrain), len(DF_LONELY_Xtest), len(DF_LONELY_Ytest))\n",
    "\n",
    "DF_NORMAL_Xtrain, DF_NORMAL_Xtest, DF_NORMAL_Ytrain, DF_NORMAL_Ytest = train_test_split(\n",
    "    DF_NORMAL.tweets,\n",
    "    DF_NORMAL.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_NORMAL.labels)\n",
    "print(len(DF_NORMAL_Xtrain), len(DF_NORMAL_Ytrain), len(DF_NORMAL_Xtest), len(DF_NORMAL_Ytest))\n",
    "\n",
    "DF_ANXIOUS_Xtrain, DF_ANXIOUS_Xtest, DF_ANXIOUS_Ytrain, DF_ANXIOUS_Ytest = train_test_split(\n",
    "    DF_ANXIOUS.tweets,\n",
    "    DF_ANXIOUS.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_ANXIOUS.labels)\n",
    "print(len(DF_ANXIOUS_Xtrain), len(DF_ANXIOUS_Ytrain), len(DF_ANXIOUS_Xtest), len(DF_ANXIOUS_Ytest))\n",
    "\n",
    "DF_STRESSED_Xtrain, DF_STRESSED_Xtest, DF_STRESSED_Ytrain, DF_STRESSED_Ytest = train_test_split(\n",
    "    DF_STRESSED.tweets,\n",
    "    DF_STRESSED.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_STRESSED.labels)\n",
    "print(len(DF_STRESSED_Xtrain), len(DF_STRESSED_Ytrain), len(DF_STRESSED_Xtest), len(DF_STRESSED_Ytest))\n",
    "\n",
    "DF_DEPRESSIVE_Xtrain, DF_DEPRESSIVE_Xtest, DF_DEPRESSIVE_Ytrain, DF_DEPRESSIVE_Ytest = train_test_split(\n",
    "    DF_DEPRESSIVE.tweets,\n",
    "    DF_DEPRESSIVE.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_DEPRESSIVE.labels)\n",
    "print(len(DF_DEPRESSIVE_Xtrain), len(DF_DEPRESSIVE_Ytrain), len(DF_DEPRESSIVE_Xtest), len(DF_DEPRESSIVE_Ytest))\n",
    "\n",
    "DF_SUICIDAL_Xtrain, DF_SUICIDAL_Xtest, DF_SUICIDAL_Ytrain, DF_SUICIDAL_Ytest = train_test_split(\n",
    "    DF_SUICIDAL.tweets,\n",
    "    DF_SUICIDAL.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_SUICIDAL.labels)\n",
    "print(len(DF_SUICIDAL_Xtrain), len(DF_SUICIDAL_Ytrain), len(DF_SUICIDAL_Xtest), len(DF_SUICIDAL_Ytest))\n",
    "\n",
    "DF_POSITIVE_Xtrain, DF_POSITIVE_Xtest, DF_POSITIVE_Ytrain, DF_POSITIVE_Ytest = train_test_split(\n",
    "    DF_POSITIVE.tweets,\n",
    "    DF_POSITIVE.labels,\n",
    "    test_size=0.2,\n",
    "    random_state=2022,\n",
    "    stratify=DF_POSITIVE.labels)\n",
    "print(len(DF_POSITIVE_Xtrain), len(DF_POSITIVE_Ytrain), len(DF_POSITIVE_Xtest), len(DF_POSITIVE_Ytest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b45e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278146    Positive\n",
      "956214     Positive\n",
      "Name: labels, dtype: object\n",
      "18626    Suicidal\n",
      "10708    Suicidal\n",
      "Name: labels, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gokz\\AppData\\Local\\Temp\\ipykernel_25296\\3394142333.py:10: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(DF_POSITIVE_Ytrain_under[:2])\n",
      "C:\\Users\\gokz\\AppData\\Local\\Temp\\ipykernel_25296\\3394142333.py:16: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  print(DF_SUICIDAL_Ytrain_over[:2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_train_size=15000\n",
    "default_test_size=3000\n",
    "positive_train_size=40000\n",
    "positive_test_size=8000\n",
    "\n",
    "DF_POSITIVE_Xtrain_under = DF_POSITIVE_Xtrain.sample(positive_train_size)\n",
    "DF_POSITIVE_Ytrain_under = DF_POSITIVE_Ytrain.sample(positive_train_size)\n",
    "DF_POSITIVE_Xtest_under = DF_POSITIVE_Xtest.sample(positive_test_size)\n",
    "DF_POSITIVE_Ytest_under = DF_POSITIVE_Ytest.sample(positive_test_size)\n",
    "print(DF_POSITIVE_Ytrain_under[:2])\n",
    "\n",
    "DF_SUICIDAL_Xtrain_over = DF_SUICIDAL_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_SUICIDAL_Ytrain_over = DF_SUICIDAL_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_SUICIDAL_Xtest_over = DF_SUICIDAL_Xtest.sample(default_test_size,replace=True)\n",
    "DF_SUICIDAL_Ytest_over = DF_SUICIDAL_Ytest.sample(default_test_size,replace=True)\n",
    "print(DF_SUICIDAL_Ytrain_over[:2])\n",
    "\n",
    "DF_DEPRESSIVE_Xtrain_over = DF_DEPRESSIVE_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_DEPRESSIVE_Ytrain_over = DF_DEPRESSIVE_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_DEPRESSIVE_Xtest_over = DF_DEPRESSIVE_Xtest.sample(default_test_size,replace=True)\n",
    "DF_DEPRESSIVE_Ytest_over = DF_DEPRESSIVE_Ytest.sample(default_test_size,replace=True)\n",
    "\n",
    "DF_STRESSED_Xtrain_over = DF_STRESSED_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_STRESSED_Ytrain_over = DF_STRESSED_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_STRESSED_Xtest_over = DF_STRESSED_Xtest.sample(default_test_size,replace=True)\n",
    "DF_STRESSED_Ytest_over = DF_STRESSED_Ytest.sample(default_test_size,replace=True)\n",
    "\n",
    "DF_ANXIOUS_Xtrain_over = DF_ANXIOUS_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_ANXIOUS_Ytrain_over = DF_ANXIOUS_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_ANXIOUS_Xtest_over = DF_ANXIOUS_Xtest.sample(default_test_size,replace=True)\n",
    "DF_ANXIOUS_Ytest_over = DF_ANXIOUS_Ytest.sample(default_test_size,replace=True)\n",
    "\n",
    "DF_NORMAL_Xtrain_over = DF_NORMAL_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_NORMAL_Ytrain_over = DF_NORMAL_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_NORMAL_Xtest_over = DF_NORMAL_Xtest.sample(default_test_size,replace=True)\n",
    "DF_NORMAL_Ytest_over = DF_NORMAL_Ytest.sample(default_test_size,replace=True)\n",
    "\n",
    "DF_LONELY_Xtrain_over = DF_LONELY_Xtrain.sample(default_train_size,replace=True)\n",
    "DF_LONELY_Ytrain_over = DF_LONELY_Ytrain.sample(default_train_size,replace=True)\n",
    "DF_LONELY_Xtest_over = DF_LONELY_Xtest.sample(default_test_size,replace=True)\n",
    "DF_LONELY_Ytest_over = DF_LONELY_Ytest.sample(default_test_size,replace=True)\n",
    "\n",
    "type(DF_LONELY_Ytest_over)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a0caac0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1278146    Positive\n",
      "956214     Positive\n",
      "974637     Positive\n",
      "1532788    Positive\n",
      "1081964    Positive\n",
      "             ...   \n",
      "8672         Lonely\n",
      "25101        Lonely\n",
      "14497        Lonely\n",
      "15707        Lonely\n",
      "14497        Lonely\n",
      "Name: labels, Length: 130000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.concat([DF_POSITIVE_Xtrain_under,DF_SUICIDAL_Xtrain_over,DF_DEPRESSIVE_Xtrain_over,\n",
    "           DF_STRESSED_Xtrain_over,DF_ANXIOUS_Xtrain_over,DF_NORMAL_Xtrain_over,DF_LONELY_Xtrain_over])\n",
    "Y_train = pd.concat([DF_POSITIVE_Ytrain_under,DF_SUICIDAL_Ytrain_over,DF_DEPRESSIVE_Ytrain_over,\n",
    "           DF_STRESSED_Ytrain_over,DF_ANXIOUS_Ytrain_over,DF_NORMAL_Ytrain_over,DF_LONELY_Ytrain_over])\n",
    "X_test = pd.concat([DF_POSITIVE_Xtest_under,DF_SUICIDAL_Xtest_over,DF_DEPRESSIVE_Xtest_over,\n",
    "           DF_STRESSED_Xtest_over,DF_ANXIOUS_Xtest_over,DF_NORMAL_Xtest_over,DF_LONELY_Xtest_over])\n",
    "Y_test = pd.concat([DF_POSITIVE_Ytest_under,DF_SUICIDAL_Ytest_over,DF_DEPRESSIVE_Ytest_over,\n",
    "           DF_STRESSED_Ytest_over,DF_ANXIOUS_Ytest_over,DF_NORMAL_Ytest_over,DF_LONELY_Ytest_over])\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "38877569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        @catiams  oh bummer! :S how are your exams goi...\n",
      "1               @Andie02 get ready for the beach tomorrow \n",
      "2            today is going to be fun! party all day long \n",
      "3             news flash!! alxm5 just sold his iphone lol \n",
      "4        @Vosty Morning Wormie  Been here for a while, ...\n",
      "                               ...                        \n",
      "25995             hard day love alive thats huge progress \n",
      "25996    people suffer know difficult mourn one person ...\n",
      "25997    love people love cause im type show love right...\n",
      "25998    advisor tell instead try game market need put ...\n",
      "25999    might get treat vote video entry celebrate lov...\n",
      "Name: tweets, Length: 26000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "X_train=X_train.reset_index(drop=True)\n",
    "X_test=X_test.reset_index(drop=True)\n",
    "Y_train=Y_train.reset_index(drop=True)\n",
    "Y_test=Y_test.reset_index(drop=True)\n",
    "\n",
    "print(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b769d8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                  hey twiter, I'm back..! \n",
      "1    Good afternoon @SwaqqedOutMissy  baby \n",
      "2                  @damonDCclark Wallace's \n",
      "Name: tweets, dtype: object\n",
      "0    Positive\n",
      "1    Positive\n",
      "2    Positive\n",
      "Name: labels, dtype: object\n",
      "0    @catiams  oh bummer! :S how are your exams goi...\n",
      "1           @Andie02 get ready for the beach tomorrow \n",
      "2        today is going to be fun! party all day long \n",
      "Name: tweets, dtype: object\n",
      "0    Positive\n",
      "1    Positive\n",
      "2    Positive\n",
      "Name: labels, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(X_train[:3])\n",
    "print(Y_train[:3])\n",
    "print(X_test[:3])\n",
    "print(Y_test[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fdc7d1",
   "metadata": {},
   "source": [
    "Görüldüğü üzere oranlar çok dengesiz. Dengelenmeye ihtiyacı var"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9239f1a",
   "metadata": {},
   "source": [
    "## Preprocessing and Balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9ff748b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(tweet):\n",
    "#     print(tweet)\n",
    "    ans = tweet.lower() # lowercase\n",
    "    ans = re.sub('@[^\\s]+', '', ans)   # remove mentions\n",
    "    soup = BeautifulSoup(unescape(ans), 'lxml')\n",
    "    ans = soup.text\n",
    "#     print(\"after -----------\")\n",
    "    ans = EMOJI_PATTERN.sub(r'', ans)  #remove emojis TODO: remove also symbols like :) :D vs.\n",
    "    ans = re.sub(r'http\\S+', '', ans)  # remove links\n",
    "    ans = \" \".join(ans.split())        # remove unnecessarily spaces\n",
    "    \n",
    "    data = nlp(ans)\n",
    "    filtered_tokens=[]\n",
    "    for token in data:\n",
    "        if token.is_stop or token.is_punct:\n",
    "            continue;\n",
    "        filtered_tokens.append(token.lemma_) #lemmatizes token\n",
    "\n",
    "    ans = \" \".join(filtered_tokens) \n",
    "    \n",
    "#     print(ans)\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1d98cf96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                       | 0/130000 [00:00<?, ?it/s]C:\\Users\\gokz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 130000/130000 [14:20<00:00, 151.00it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train_processed = X_train.copy()\n",
    "tqdm.pandas()\n",
    "X_train_processed = X_train_processed.progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fd7374bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/26000 [00:00<?, ?it/s]C:\\Users\\gokz\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 26000/26000 [02:45<00:00, 156.86it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test_processed = X_test.copy()\n",
    "tqdm.pandas()\n",
    "X_test_processed = X_test_processed.progress_apply(preprocess)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83dd2512",
   "metadata": {},
   "source": [
    "## Split test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8849b658",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0                                  hey twiter, I'm back..! \n",
       " 1                    Good afternoon @SwaqqedOutMissy  baby \n",
       " 2                                  @damonDCclark Wallace's \n",
       " 3                        @junkfoodfm Ahah sympa le concept \n",
       " 4         got my fill of great sun, great food, great fr...\n",
       "                                 ...                        \n",
       " 129995    human need job cant exist amp make art chill cat \n",
       " 129996              whyd let feel lonely love hard darkest \n",
       " 129997                                           need help \n",
       " 129998    alright go seeing 53 spoiler ban lift lost tho...\n",
       " 129999    free vice b26c4628 battle id need backup lvl 1...\n",
       " Name: tweets, Length: 130000, dtype: object,\n",
       " 0         Positive\n",
       " 1         Positive\n",
       " 2         Positive\n",
       " 3         Positive\n",
       " 4         Positive\n",
       "             ...   \n",
       " 129995      Lonely\n",
       " 129996      Lonely\n",
       " 129997      Lonely\n",
       " 129998      Lonely\n",
       " 129999      Lonely\n",
       " Name: labels, Length: 130000, dtype: object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train,Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0d634aaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                  hey twiter, I'm back..! \n",
       "1                    Good afternoon @SwaqqedOutMissy  baby \n",
       "2                                  @damonDCclark Wallace's \n",
       "3                        @junkfoodfm Ahah sympa le concept \n",
       "4         got my fill of great sun, great food, great fr...\n",
       "                                ...                        \n",
       "129995    human need job cant exist amp make art chill cat \n",
       "129996              whyd let feel lonely love hard darkest \n",
       "129997                                           need help \n",
       "129998    alright go seeing 53 spoiler ban lift lost tho...\n",
       "129999    free vice b26c4628 battle id need backup lvl 1...\n",
       "Name: tweets, Length: 130000, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_processed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bdd56d",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e5b395",
   "metadata": {},
   "source": [
    "MultinomialNB | Unigram | Processed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68f4dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxious       0.34      0.45      0.39      3000\n",
      "  Depressive       0.59      0.67      0.63      3000\n",
      "      Lonely       0.39      0.41      0.40      3000\n",
      "      Normal       0.85      0.38      0.53      3000\n",
      "    Positive       0.93      0.92      0.93      8000\n",
      "    Stressed       0.83      0.85      0.84      3000\n",
      "    Suicidal       0.60      0.64      0.62      3000\n",
      "\n",
      "    accuracy                           0.68     26000\n",
      "   macro avg       0.65      0.62      0.62     26000\n",
      "weighted avg       0.70      0.68      0.68     26000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_mb1=Pipeline([\n",
    "    ('vectorizer_bow',CountVectorizer()),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "classifier_mb1.fit(X_train,Y_train)\n",
    "Y_pred= classifier_mb1.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8144483c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxious       0.31      0.40      0.35      3000\n",
      "  Depressive       0.59      0.68      0.63      3000\n",
      "      Lonely       0.37      0.41      0.39      3000\n",
      "      Normal       0.93      0.31      0.46      3000\n",
      "    Positive       0.91      0.91      0.91      8000\n",
      "    Stressed       0.86      0.88      0.87      3000\n",
      "    Suicidal       0.60      0.66      0.63      3000\n",
      "\n",
      "    accuracy                           0.66     26000\n",
      "   macro avg       0.65      0.61      0.61     26000\n",
      "weighted avg       0.70      0.66      0.66     26000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_mb2=Pipeline([\n",
    "    ('vectorizer_bow',CountVectorizer(ngram_range=(1,2))),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "classifier_mb2.fit(X_train,Y_train)\n",
    "Y_pred= classifier_mb2.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3e6ece10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     Anxious       0.31      0.40      0.35      3000\n",
      "  Depressive       0.57      0.67      0.61      3000\n",
      "      Lonely       0.37      0.41      0.39      3000\n",
      "      Normal       0.95      0.27      0.42      3000\n",
      "    Positive       0.89      0.90      0.90      8000\n",
      "    Stressed       0.87      0.87      0.87      3000\n",
      "    Suicidal       0.58      0.64      0.61      3000\n",
      "\n",
      "    accuracy                           0.65     26000\n",
      "   macro avg       0.65      0.60      0.59     26000\n",
      "weighted avg       0.69      0.65      0.65     26000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "classifier_mb3=Pipeline([\n",
    "    ('vectorizer_bow',CountVectorizer(ngram_range=(1,3))),\n",
    "    ('Multi NB', MultinomialNB())\n",
    "])\n",
    "classifier_mb3.fit(X_train,Y_train)\n",
    "Y_pred= classifier_mb3.predict(X_test)\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "95f36a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suicidal' 'Positive' 'Positive' 'Depressive' 'Suicidal' 'Suicidal'\n",
      " 'Suicidal' 'Depressive' 'Positive' 'Stressed']\n"
     ]
    }
   ],
   "source": [
    "manual_test_list=[\"I want to kill myself\",\n",
    "                  \"awesome, everything is okay\",\n",
    "                  \"thank you so much\",\n",
    "                  \"moving another country\",\n",
    "                  \"i hate all of you and going to kill myself\",\n",
    "                  \"what is the point of living?\",\n",
    "                  \"death is everywhere\",\n",
    "                  \"overcome depression\",\n",
    "                  \"song is great\",\n",
    "                  \"i saw a sad woman\"]\n",
    "\n",
    "sonuc1=classifier_mb2.predict(manual_test_list)\n",
    "print(sonuc1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ebc83a9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Suicidal' 'Positive' 'Positive' 'Stressed' 'Suicidal' 'Suicidal'\n",
      " 'Suicidal' 'Depressive' 'Positive' 'Stressed']\n"
     ]
    }
   ],
   "source": [
    "sonuc_list = [preprocess(text) for text in manual_test_list]\n",
    "\n",
    "sonuc1=classifier_mb3.predict(sonuc_list)\n",
    "print(sonuc1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6968bc60",
   "metadata": {},
   "source": [
    "## Export modal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "47d141c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "classifier_file=open(\"mental_illness_detector.pkl\",\"wb\")\n",
    "joblib.dump(classifier_mb2,classifier_file)\n",
    "classifier_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3d4f163",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "a2411544f02ed3f59dda0fdf82b48ebed239454fb0c73192eba5c16e1d8cc24e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
